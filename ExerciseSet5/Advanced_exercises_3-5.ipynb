{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>3. Download the \"complex.xml\" file from Moodle, and create a DataFrame out of it.</b></li>\n",
    "<ul>\n",
    "    <li><b>Note:</b> using pandas.read_xml() would otherwise work, but it ignores the \"ownership\" –field. You'll have to find another way to get this data into your DataFrame as well!</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the common data analytics modules\n",
    "import requests\n",
    "import json\n",
    "import xml.etree.ElementTree as et \n",
    "from flatten_json import flatten\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>company</th>\n",
       "      <th>acquired</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>iban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mazda</td>\n",
       "      <td>B-Series Plus</td>\n",
       "      <td>1994</td>\n",
       "      <td>69221</td>\n",
       "      <td>Mueller-VonRueden</td>\n",
       "      <td>25/3/2020</td>\n",
       "      <td>jcb</td>\n",
       "      <td>LU43 964Q PJUD Z9WI JVSR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F350</td>\n",
       "      <td>2006</td>\n",
       "      <td>13859</td>\n",
       "      <td>Simonis, Graham and Veum</td>\n",
       "      <td>6/4/2020</td>\n",
       "      <td>diners-club-enroute</td>\n",
       "      <td>AE82 5889 6103 2911 2983 729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BMW</td>\n",
       "      <td>7 Series</td>\n",
       "      <td>2012</td>\n",
       "      <td>78125</td>\n",
       "      <td>Hammes LLC</td>\n",
       "      <td>25/12/2017</td>\n",
       "      <td>jcb</td>\n",
       "      <td>AZ52 PNUH TWPT YQY9 RMLE BMXO 4JIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Baja</td>\n",
       "      <td>2004</td>\n",
       "      <td>32941</td>\n",
       "      <td>MacGyver, Oberbrunner and McGlynn</td>\n",
       "      <td>2/6/2019</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>FR22 5863 0754 268V RGIQ GHX5 Y27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Audi</td>\n",
       "      <td>S6</td>\n",
       "      <td>2007</td>\n",
       "      <td>46761</td>\n",
       "      <td>Hand, Johnston and Hickle</td>\n",
       "      <td>12/10/2016</td>\n",
       "      <td>jcb</td>\n",
       "      <td>LT37 9834 6062 9512 0523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id   brand          model  year  price                            company  \\\n",
       "0  1   Mazda  B-Series Plus  1994  69221                  Mueller-VonRueden   \n",
       "1  2    Ford           F350  2006  13859           Simonis, Graham and Veum   \n",
       "2  3     BMW       7 Series  2012  78125                         Hammes LLC   \n",
       "3  4  Subaru           Baja  2004  32941  MacGyver, Oberbrunner and McGlynn   \n",
       "4  5    Audi             S6  2007  46761          Hand, Johnston and Hickle   \n",
       "\n",
       "     acquired          credit_card                                iban  \n",
       "0   25/3/2020                  jcb            LU43 964Q PJUD Z9WI JVSR  \n",
       "1    6/4/2020  diners-club-enroute        AE82 5889 6103 2911 2983 729  \n",
       "2  25/12/2017                  jcb  AZ52 PNUH TWPT YQY9 RMLE BMXO 4JIT  \n",
       "3    2/6/2019           mastercard   FR22 5863 0754 268V RGIQ GHX5 Y27  \n",
       "4  12/10/2016                  jcb            LT37 9834 6062 9512 0523  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load XML-file, get root node\n",
    "xtree = et.parse(\"complex.xml\")\n",
    "nodes = xtree.getroot()\n",
    "\n",
    "# column names for pandas to create DataFrame later\n",
    "df_cols = [\"id\", \"brand\", \"model\", \"year\", \"price\", \"company\", \"acquired\", \"credit_card\", \"iban\"]\n",
    "rows = []\n",
    "\n",
    "for node in nodes.iter(\"car\"):\n",
    "    # parse values\n",
    "    e_id = node.find(\"id\").text\n",
    "    e_brand = node.find(\"brand\").text\n",
    "    e_model = node.find(\"model\").text\n",
    "    e_year = node.find(\"year\").text\n",
    "    e_price = node.find(\"price\").text\n",
    "\n",
    "    # parse nested values\n",
    "    ownership = node.find(\"ownership\")\n",
    "    e_company = ownership.find(\"company\").text\n",
    "    e_acquired = ownership.find(\"acquired\").text\n",
    "\n",
    "    payment_info = ownership.find(\"payment_info\")\n",
    "    e_credit_card = payment_info.find(\"credit_card\").text\n",
    "    e_iban = payment_info.find(\"iban\").text\n",
    "\n",
    "    # append values to rows\n",
    "    rows.append({\"id\": e_id, \"brand\": e_brand, \"model\": e_model, \"year\": e_year, \"price\": e_price, \"company\": e_company, \"acquired\": e_acquired, \"credit_card\": e_credit_card, \"iban\": e_iban})\n",
    "\n",
    "# create DataFrame\n",
    "out_df = pd.DataFrame(rows, columns = df_cols)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>4. Try out Selenium on a site that cannot be scraped with traditional methods. You can use this tutorial as the starting point:</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.toptal.com/python/web-scraping-with-python\">https://www.toptal.com/python/web-scraping-with-python</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selenium components\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Establish chrome driver and go to report site URL\n",
    "url = \"https://reportdata.mytestsite.com/transactionSearch.jsp\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Extra challenging advanced task: <span style=\"color: red;\">integrating data sources</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Integrate two or more datasets into one matching dataset  (pandas DataFrame), but use any datasets you can find in Kaggle instead of the previous coffee sales + temperature -datasets</b></li>\n",
    "<br />\n",
    "<ul>\n",
    "<li>Find two or more datasets (Kaggle etc.) that have something in common and can be used for merging. </li>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>Typical common columns:</b></li>\n",
    "<ul>\n",
    "<li>Coordinates (lat/lng etc.)</li>\n",
    "<li>Years, months</li>\n",
    "<li>reference ids (e.g. product id -> product data)</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>You can use pandas.merge() in order to combine DataFrames</b></li>\n",
    "<ul>\n",
    "<li>When combining DataFrames, make sure that the merge doesn’t mess up your data</li>\n",
    "<li><b>Note:</b> merge can often create way too many extra rows depending on the merging parameters</li>\n",
    "\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>This exercise can provide even large amounts of points, depending on difficulty. Aspects that affect grading:</b></li>\n",
    "<ul>\n",
    "<li>Amount of datasets</li>\n",
    "<li>Difficulty of the datasets</li>\n",
    "<li>Using different data formats all at once (XML, JSON, CSV etc.)</li>\n",
    "<li>Other techniques used to add data: web scraping, data APIs etc.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
